{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Land"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Create folders for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the date we run this code\n",
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "# folder_bf is used for storing brownfield data\n",
    "folder_prj = 'Data/'+timestamp\n",
    "if not os.path.exists(folder_prj):\n",
    "    os.makedirs(folder_prj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1 brownfield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_bf is used for storing brownfield data\n",
    "folder_bf = 'Data/'+timestamp+'/Brownfield/' \n",
    "if not os.path.exists(folder_bf):\n",
    "    os.makedirs(folder_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n",
    "headers=eval(input('headers:'))\n",
    "\n",
    "#{'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:98.0) Gecko/20100101 Firefox/98.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapy(url, select, headers):\n",
    "    res = requests.get(url,headers=headers)\n",
    "    soup=BeautifulSoup(res.text,'html.parser')\n",
    "    url=soup.select(select)\n",
    "    file_url=url[0].get('href')\n",
    "    \n",
    "    return file_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oldham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first url\n",
    "urlO='https://www.oldham.gov.uk/homepage/1386/brownfield_land_register'\n",
    "selectO = '#content > div:nth-child(2) > div > div > div > div:nth-child(2) > div > ul:nth-child(24) > li:nth-child(1) > a'\n",
    "file_url_O=scrapy(urlO,selectO,headers)\n",
    "\n",
    "#sub_url\n",
    "selectO2='#content > ul > li > div > a'\n",
    "file_url_02=scrapy(file_url_O,selectO2,headers)\n",
    "\n",
    "#sub_sub_url\n",
    "selectO3='#content > a'\n",
    "file_url_O3=scrapy(file_url_02,selectO3,headers)\n",
    "\n",
    "# download datset\n",
    "file_pathO =folder_bf +'/Oldham.csv'\n",
    "request.urlretrieve(file_url_O3, file_pathO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rochdale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlR='http://www.rochdale.gov.uk/planning-and-building/Pages/brownfield-land-register.aspx'\n",
    "selectR='#ctl00_PlaceHolderMain_ctl02__ControlWrapper_RichHtmlField > ul:nth-child(19) > li:nth-child(5) > a'\n",
    "file_url_R=scrapy(urlR,selectR,headers)\n",
    "print(file_url_R)\n",
    "file_url_R = 'http://www.rochdale.gov.uk'+file_url_R\n",
    "file_pathR=folder_bf +'/Rochdale.csv'\n",
    "request.urlretrieve(file_url_R, file_pathR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlS='https://www.salford.gov.uk/brownfield-register'\n",
    "selectS='#standard-page > div:nth-child(1) > div.col-xs-12.col-md-8 > div > ul > li:nth-child(2) > a'\n",
    "file_url_S=scrapy(urlS,selectS,headers)\n",
    "file_url_S = 'https://www.salford.gov.uk'+file_url_S\n",
    "file_pathS=folder_bf +'/Salford.csv'\n",
    "request.urlretrieve(file_url_S, file_pathS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bolton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlB = 'https://www.bolton.gov.uk/planning-policy-strategy/brownfield-register'\n",
    "selectB = '#content > div > div > div > article > div > p:nth-child(2) > a'\n",
    "file_url_B=scrapy(urlB,selectB,headers)\n",
    "file_pathB=folder_bf +'/Bolton.csv'\n",
    "request.urlretrieve(file_url_B, file_pathB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manchester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first url\n",
    "urlM = 'https://www.manchester.gov.uk/info/200074/planning/7293/brownfield_register_pilot'\n",
    "selectM ='#content > section > article > p > a:nth-child(1)'\n",
    "file_url_M=scrapy(urlM,selectM,headers)\n",
    "\n",
    "#sub_url\n",
    "selectM2='#content > section > article > h3 > a'\n",
    "file_url_M2=scrapy(file_url_M,selectM2,headers)\n",
    "\n",
    "file_pathM =folder_bf +'/Manchester.csv'\n",
    "request.urlretrieve(file_url_M2, file_pathM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlBU='https://www.bury.gov.uk/index.aspx?articleid=11050'\n",
    "selectBU='#download > div > div:nth-child(1) > div.odd > div > a'\n",
    "file_url_BU=scrapy(urlBU,selectBU,headers)\n",
    "file_pathBU=folder_bf +'/Bury.csv'\n",
    "request.urlretrieve(file_url_BU, file_pathBU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trafford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlT='https://www.trafford.gov.uk/planning/strategic-planning/local-plan/brownfield-land-register.aspx'\n",
    "selectT='#main-article > p:nth-child(8) > a'\n",
    "file_url_T=scrapy(urlT,selectT,headers)\n",
    "file_url_T = 'https://www.trafford.gov.uk'+file_url_T\n",
    "file_pathT=folder_bf +'/Trafford.csv'\n",
    "request.urlretrieve(file_url_T, file_pathT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wigan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#'https://www.wigan.gov.uk/Council/Strategies-Plans-and-Policies/Planning/Brownfield-register.aspx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlW='https://data.gov.uk/dataset/2a962992-277a-4fa2-ab81-1065da56df3d/brownfield'\n",
    "selectW='#content > div > div > div > section > table > tbody > tr:nth-child(4) > td:nth-child(1) > a'\n",
    "file_url_W=scrapy(urlW,selectW,headers)\n",
    "file_pathW=folder_bf +'/Wigan.csv'\n",
    "request.urlretrieve(file_url_W, file_pathW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stockport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first url\n",
    "urlST='https://www.stockport.gov.uk/brownfield/brownfield-land-register'\n",
    "selectST='#uitest-page-has-loaded > section > div > div > div:nth-child(3) > article > p:nth-child(6) > a'\n",
    "file_url_ST=scrapy(urlST,selectST,headers)\n",
    "\n",
    "# sub_url\n",
    "selectST2='#content > div > div > div > section > table > tbody > tr:nth-child(1) > td:nth-child(1) > a'\n",
    "file_url_ST2=scrapy(file_url_ST,selectST2,headers)\n",
    "\n",
    "file_pathST=folder_bf +'/Stockport.csv'\n",
    "request.urlretrieve(file_url_ST2, file_pathST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tameside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlTA='https://www.tameside.gov.uk/planning/brownfieldregister'\n",
    "selectTA='#manincontent > ul > li:nth-child(2) > a'\n",
    "file_url_TA=scrapy(urlTA,selectTA,headers)\n",
    "file_url_TA = 'https://www.tameside.gov.uk'+file_url_TA\n",
    "file_pathTA=folder_bf +'/Tameside.csv'\n",
    "request.urlretrieve(file_url_TA, file_pathTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 download data about factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_fac is used for storing datasets about factors\n",
    "folder_fac = 'Data/'+timestamp+'/Factors/'\n",
    "if not os.path.exists(folder_fac):\n",
    "    os.makedirs(folder_fac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bus station\n",
    "urlBus='https://data.gov.uk/dataset/05252e3a-acdf-428b-9314-80ac7b17ab76/gm-bus-stopping-points'\n",
    "selectBus='#content > div > div > div > section > table > tbody > tr:nth-child(2) > td:nth-child(1) > a'\n",
    "file_url_Bus=scrapy(urlBus,selectBus,headers)\n",
    "file_path_Bus=folder_fac +'/Bus.csv'\n",
    "request.urlretrieve(file_url_Bus, file_path_Bus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#education \n",
    "file_path_edu = folder_fac + '/education.zip'\n",
    "file_url_edu = 'https://map.salford.gov.uk/geoserver/NE_open/ows?service=WFS&version=1.0.0&request=GetFeature&typeName=NE_open:v_gm_education_establishments&outputFormat=SHAPE-ZIP'\n",
    "request.urlretrieve(file_url_edu, file_path_edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#youth_centers\n",
    "file_path_youth = folder_fac + '/youth_centers.zip' \n",
    "file_url_youth ='https://map.salford.gov.uk/geoserver/NE_open/ows?service=WFS&version=1.0.0&request=GetFeature&typeName=NE_open:v_gm_youth_centres&outputFormat=SHAPE-ZIP'\n",
    "request.urlretrieve(file_url_youth,file_path_youth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leisure_centers\n",
    "file_path_leisure = folder_fac + '/leisure_centers.zip' \n",
    "file_url_leisure = 'https://map.salford.gov.uk/geoserver/NE_open/ows?service=WFS&version=1.0.0&request=GetFeature&typeName=NE_open:v_gm_leisure_centres&outputFormat=SHAPE-ZIP'\n",
    "request.urlretrieve(file_url_leisure,file_path_leisure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cycle Hubs\n",
    "file_path_cycle = folder_fac + '/cycle_hubs.zip' \n",
    "file_url_cycle ='https://odata.tfgm.com/opendata/downloads/CycleMaps/Cycle_Hubs.zip'\n",
    "request.urlretrieve(file_url_cycle,file_path_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Air Pollution\n",
    "file_path_pollution = folder_fac + '/air_pollution.zip' \n",
    "file_url_pollution ='https://uk-air.defra.gov.uk/assets/documents/uk_aqma_080322_v_4.zip'\n",
    "request.urlretrieve(file_url_pollution,file_path_pollution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Risk of Flooding from Rivers and Sea \n",
    "file_path_flooding = folder_fac + '/flooding.zip' \n",
    "file_url_flooding ='https://environment.data.gov.uk/UserDownloads/interactive/4f0ac75a2b794baaa403020b6c36e09d11220/EA_RiskOfFloodingFromRiversAndSea_SHP_Full.zip'\n",
    "request.urlretrieve(file_url_flooding,file_path_flooding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Children_centers\n",
    "file_path_children = folder_fac + '/childrens_centers.zip' \n",
    "file_url_children = 'https://map.salford.gov.uk/geoserver/NE_open/ows?service=WFS&version=1.0.0&request=GetFeature&typeName=NE_open:v_gm_childrens_centres&outputFormat=SHAPE-ZIP'\n",
    "request.urlretrieve(file_url_children,file_path_children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#office land\n",
    "file_path_office = folder_fac + '/office_land.zip' \n",
    "file_url_office = 'https://map.salford.gov.uk/geoserver/NE_open/ows?service=WFS&version=1.0.0&request=GetFeature&typeName=NE_open:v_gmsf_office_land_2020&outputFormat=SHAPE-ZIP'\n",
    "request.urlretrieve(file_url_office,file_path_office)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boundaries of UK(by local authorities)\n",
    "file_path_boundary = folder_fac + '/infuse_dist_lyr_2011_clipped.zip' \n",
    "file_url_boundary = 'https://borders.ukdataservice.ac.uk/ukborders/easy_download/prebuilt/shape/infuse_dist_lyr_2011_clipped.zip'\n",
    "request.urlretrieve(file_url_boundary,file_path_boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_shp is used for storing shp files and analyse result\n",
    "folder_shp = 'Data/'+timestamp+'/SHP/'\n",
    "if not os.path.exists(folder_shp):\n",
    "    os.makedirs(folder_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to remove files from old path and transfer them to new path\n",
    "def remove_file(old_path, new_path):\n",
    "    filelist = os.listdir(old_path) \n",
    "    for file in filelist:\n",
    "        src = os.path.join(old_path, file)\n",
    "        dst = os.path.join(new_path, file)\n",
    "        shutil.move(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to unzip .zip files\n",
    "# 'directory' refers to the directory where the zip file sits. ' extract_dir' is the diretory for unpacked files. \n",
    "def unzip_file(directory, filename, extract_dir):\n",
    "    zip_file = directory + filename\n",
    "    archive_format = 'zip'\n",
    "    shutil.unpack_archive(zip_file, extract_dir, archive_format)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "directory = folder_fac\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".zip\"):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename == 'cycle_hubs.zip':\n",
    "            #unzip files\n",
    "            unzip_file(directory, filename, folder_fac)\n",
    "            #only transfer SHP files to shp directory\n",
    "            transfer_dir=folder_fac+'SHP-format'\n",
    "            remove_file(transfer_dir, folder_shp)\n",
    "            print(filename,'>>> extracted success')\n",
    "        elif filename == 'flooding.zip':\n",
    "            #unzip files\n",
    "            unzip_file(directory, filename, folder_fac)\n",
    "            #only transfer SHP files to shp directory\n",
    "            transfer_dir=folder_fac+'data'\n",
    "            remove_file(transfer_dir, folder_shp)\n",
    "            print(filename,'>>> extracted success')\n",
    "        else:\n",
    "            unzip_file(directory, filename, folder_shp)\n",
    "            print(filename,'>>> extracted success')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 preprocessing the brownfield data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select value and convert the location to the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob,os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import datasets\n",
    "path = folder_bf\n",
    "file = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "dl = []\n",
    "for f in file:\n",
    "    dl.append(pd.read_csv(f,encoding='ISO-8859-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Select four features: Authority, SiteNameAddress, GeoX, GeoY, Hectares\n",
    "# Get each datasets' file name\n",
    "file_names=[]\n",
    "for i in file:\n",
    "    file_name = os.path.basename(i)[:-4]\n",
    "    file_names.append(file_name)\n",
    "print(file_names)\n",
    "    \n",
    "# Select features\n",
    "dl2=[]\n",
    "for i in file_names:\n",
    "    file_name = i\n",
    "    if i != 'Rochdale':\n",
    "        index = file_names.index(i)\n",
    "        df=dl[index]\n",
    "        df=df[['SiteNameAddress','GeoX','GeoY','Hectares']]\n",
    "        df['Authority']=file_name\n",
    "        dl2.append(df)\n",
    "    else:\n",
    "        index = file_names.index(i)\n",
    "        df=dl[index].iloc[1:,[1,4,5,7]]\n",
    "        df.columns=['SiteNameAddress','EAST/WEST','NORTH/SOUTH','Hectares']\n",
    "        df['Authority']=file_name\n",
    "        dl2.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. Convert XY to GeoX,GeoY (Only Trafford and Rochdale )\n",
    "from pyproj import Transformer\n",
    "transformer = Transformer.from_crs(\"epsg:27700\", \"EPSG:4326\", always_xy=True)\n",
    "# Trafford\n",
    "index_T = file_names.index('Trafford')\n",
    "X=dl2[index_T]['GeoY']\n",
    "Y=dl2[index_T]['GeoX']\n",
    "transformed=transformer.transform(X,Y)\n",
    "dl2[index_T]['GeoX']=transformed[0]\n",
    "dl2[index_T]['GeoY']=transformed[1]\n",
    "\n",
    "#Rochdale\n",
    "index_R = file_names.index('Rochdale')\n",
    "X=dl2[index_R]['EAST/WEST']\n",
    "Y=dl2[index_R]['NORTH/SOUTH']\n",
    "transformed=transformer.transform(X,Y)\n",
    "dl2[index_R]['EAST/WEST']=transformed[0]\n",
    "dl2[index_R]['NORTH/SOUTH']=transformed[1]\n",
    "dl2[index_R].columns=['SiteNameAddress','GeoX','GeoY','Hectares','Authority']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 preprocessing the bus station data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factor: Bus station is also a csv file, we only need coordinates of each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = folder_fac\n",
    "file2 = glob.glob(os.path.join(path2, \"*.csv\"))\n",
    "for f in file2:\n",
    "    dl_bus=pd.read_csv(f,encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select CommonName, Longitude, Latitude\n",
    "dl_bus = dl_bus[['CommonName','Longitude','Latitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 convert the csv format to shp format and store them in shp folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Save converted files(shp)\n",
    "# 2.1 Brownfield.shp directory\n",
    "\n",
    "for i in file_names:\n",
    "    index = file_names.index(i)\n",
    "    # Create tuples of geometry by zipping longitude and latitude columns in your csv file\n",
    "    geometry = [Point(xy) for xy in zip(dl2[index].GeoX, dl2[index].GeoY)] \n",
    "    \n",
    "    # Define coordinate reference system on which to project your resulting shapefileï¼Œ USING WGS1984\n",
    "    crs = {'init': 'epsg:4326'}\n",
    "    \n",
    "    # Convert dataframe objects (containing your csv) to geodataframe objects using geodataframe\n",
    "    gdf = GeoDataFrame(dl2[index], crs = crs, geometry=geometry)\n",
    "\n",
    "    \n",
    "    #Save file to local destination\n",
    "    output_filename = folder_shp + i + \".shp\"\n",
    "    gdf.to_file(filename= output_filename, driver='ESRI Shapefile')\n",
    "print(\"Files(csv) converted to shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 convert Bus station.csv to shp file\n",
    "geometry_bus = [Point(xy) for xy in zip(dl_bus.Longitude, dl_bus.Latitude)] \n",
    "crs = {'init': 'epsg:4326'}\n",
    "gdf_bus = GeoDataFrame(dl_bus, crs = crs, geometry=geometry_bus)\n",
    "output_filename_bus = folder_shp + 'bus_station' + \".shp\"\n",
    "gdf_bus.to_file(filename= output_filename_bus, driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Read all shp file by geopands\n",
    "import geopandas as gpd\n",
    "path_shp = folder_shp\n",
    "file_shp = glob.glob(os.path.join(path_shp, \"*.shp\"))\n",
    "dl_shp = []\n",
    "for f in file_shp:\n",
    "    dl_shp.append(gpd.read_file(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Import data to ArcGIS pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing shp files to Map from a certain location\n",
    "import arcpy\n",
    "\n",
    "directory=os.getcwd() + '\\\\'+ folder_shp # in windows\n",
    "\n",
    "#the path to the project file(.aprx) can replace 'CURRENT'\n",
    "aprx = arcpy.mp.ArcGISProject(\"CURRENT\") \n",
    "arcmap = aprx.listMaps()[0]\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".shp\"):  \n",
    "        filename = os.fsdecode(file)\n",
    "        shp_file = directory + filename\n",
    "        arcmap.addDataFromPath(shp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create an analysis model to select housing land by model builder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "332.549px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
